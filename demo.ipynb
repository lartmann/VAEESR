{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "82adac62",
      "metadata": {
        "id": "82adac62"
      },
      "source": [
        "# Imports and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46eae34f",
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip3 install vaeesr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AxSPHYilaTV5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxSPHYilaTV5",
        "outputId": "71d71cdb-fb79-49f4-c59c-a7a50d3777f3"
      },
      "outputs": [],
      "source": [
        "! pip3 install seaborn colour plotly\n",
        "! pip3 install --upgrade nbformat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5bb993c",
      "metadata": {
        "id": "f5bb993c"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.onnx\n",
        "import copy\n",
        "\n",
        "# MODEL PARAMETERS\n",
        "latent_dims = 6\n",
        "max_tree_depth = 4\n",
        "num_equations = 10000\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WLFiqtFvdkXR",
      "metadata": {
        "id": "WLFiqtFvdkXR"
      },
      "source": [
        "An increased tree depth will lead to an increased number of classes. It is important to pay attention that the dataset is still much bigger than the total number of classes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IYNiH1nzZ-TD",
      "metadata": {
        "id": "IYNiH1nzZ-TD"
      },
      "source": [
        "# Helper function\n",
        "Mostly for visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "aDK4AH7AZ-TE",
      "metadata": {
        "id": "aDK4AH7AZ-TE"
      },
      "outputs": [],
      "source": [
        "def plot_losses(train_loss, test_loss, correlation_dis=None, df=None, save=None, correlations_dis_train=None, dpi=500):\n",
        "    # make subplots\n",
        "    fig, ax = plt.subplots(1, 3, sharex=True, figsize=(16, 5))\n",
        "    fig.supxlabel('Epoch')\n",
        "    fig.supylabel('Loss')\n",
        "\n",
        "    ax[0].plot(train_loss, label='Train Loss')\n",
        "    ax[0].plot(test_loss, label='Test Loss')\n",
        "    ax[0].legend()\n",
        "    ax[0].set_ylabel('Loss')\n",
        "    ax[0].set_title('Train and Test Losses')\n",
        "    #ax[0,0].suptitle('Train and Test Losses')\n",
        "    if correlation_dis is not None:\n",
        "        ax[1].plot(correlation_dis, label='Correlation_dis')\n",
        "        if correlations_dis_train is not None:\n",
        "            ax[1].plot(correlations_dis_train, label='Correlation_dis_train')\n",
        "        ax[1].legend()\n",
        "        ax[1].set_ylabel('Correlation')\n",
        "        ax[1].set_title('Correlation between latent space representation and value distance')\n",
        "        #ax[1,1].suptitle('Correlation between latent space representation and value distance')\n",
        "    if df is not None:\n",
        "        ax[2].plot(df['test_reconstruction_loss'], label='Reconstruction Loss')\n",
        "        ax[2].plot(df['test_kl_divergence'], label='KL Loss')\n",
        "        ax[2].plot(df['test_constant_loss'], label='Constant Loss')\n",
        "\n",
        "        ax[2].plot(df['test_latent_correlation_loss'], label='Distance Correlation Loss')\n",
        "        average_loss = [x/4 for x in test_loss]\n",
        "        #ax[0,1].plot(average_loss, label='Total Loss / 4')\n",
        "        ax[2].legend()\n",
        "        ax[2].set_ylabel('Loss')\n",
        "        ax[2].set_title('Individual Test Losses')\n",
        "        #ax[0,1].suptitle('Individual Test Losses')\n",
        "    fig.show()\n",
        "    if save is not None:\n",
        "        fig.savefig(save, dpi=dpi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "voHay2nxZ-TE",
      "metadata": {
        "id": "voHay2nxZ-TE"
      },
      "outputs": [],
      "source": [
        "def plot_functions(equations, values, constants, is_function, is_operator):\n",
        "    if len(equations) == 0:\n",
        "        return None\n",
        "    colors = list(Color(\"violet\").range_to(Color(\"green\"), len(equations)))\n",
        "    try:\n",
        "        fig = go.Figure(\n",
        "                data=go.Scatter(\n",
        "                    x=values[0][0],\n",
        "                    y=values[0][1],\n",
        "                    mode=\"lines\",\n",
        "                    line = dict(color = colors[0].hex,\n",
        "                                            width = 4),\n",
        "                    name=try_infix(equations[0], constants[0]),\n",
        "                )\n",
        "\n",
        "        )\n",
        "        '''\n",
        "        fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=values[0][0],\n",
        "                y=values[0][1],\n",
        "                #mode=\"lines\",\n",
        "                name=try_infix(equations[0], constants[0]),\n",
        "            )\n",
        "        )\n",
        "        '''\n",
        "        for i in range(1, len(equations)):\n",
        "            try:\n",
        "                fig.add_trace(\n",
        "                    go.Scatter(\n",
        "                        x=values[i][0],\n",
        "                        y=values[i][1],\n",
        "                        mode=\"lines\",\n",
        "                        line = dict(color = colors[i].hex,\n",
        "                                            width = 4),\n",
        "                        name= try_infix(equations[i], constants[i]),\n",
        "                    )\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(f\"failed to plot {equations[i]}\")\n",
        "\n",
        "        #plot(fig,filename=\"functions.html\",auto_open=False,image='png')\n",
        "\n",
        "    except IndexError:\n",
        "        print(\"no functions to plot\")\n",
        "        fig = None\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "LPzetWdmZ-TF",
      "metadata": {
        "id": "LPzetWdmZ-TF"
      },
      "outputs": [],
      "source": [
        "def plot_dist(smpls):\n",
        "    # Plot resulting probability distribution\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    for i in range(latent_dims):\n",
        "        sns.histplot(smpls[f'latent_variable_{i}'], kde=True, ax=ax)\n",
        "\n",
        "    # add legend\n",
        "    ax.legend([f\"latent_variable_{i}\" for i in range(latent_dims)])\n",
        "\n",
        "    ax.set_title(\"Posterior distribution of the latent variables\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3PZDIJ2EZ-TF",
      "metadata": {
        "id": "3PZDIJ2EZ-TF"
      },
      "outputs": [],
      "source": [
        "from vaeesr import decode_latent_classify, generate_values\n",
        "from equation_tree.util.conversions import prefix_to_infix\n",
        "\n",
        "def plot_sampling_functions(smpls, with_Random, latent_dims, spaces, autoencoder, dataset, classes, num_eval_samples, v_sample, v_real, v_random, target_constant, target_function, x_values):\n",
        "    is_function, is_operator, is_variable, is_constant = mapping_from_spaces(spaces)\n",
        "    # latent variabls values\n",
        "    latent_variable_MCMC = []\n",
        "    equations_MCMC = []\n",
        "    constants_MCMC = []\n",
        "    # generate a list of lists for the latent variables of each iteration (num_iterations, latent_dims)\n",
        "    for s in range(len(smpls['latent_variable_0'])):\n",
        "        embedding = []\n",
        "        for i in range(latent_dims):\n",
        "            embedding.append(smpls[f'latent_variable_{i}'][s].item())\n",
        "        equations, constants = decode_latent_classify(autoencoder, dataset, [embedding], classes)\n",
        "        values = torch.tensor(generate_values(equations[0], constants[0][0][0], is_function, is_operator, is_variable, is_constant)[1], dtype=torch.float32)\n",
        "        latent_variable_MCMC += values.detach().numpy().tolist()\n",
        "        constants_MCMC += [constants[0][0][0]]*num_eval_samples\n",
        "        equations_MCMC += [prefix_to_infix(equations[0], is_function, is_operator).replace('x_1', 'x').replace('c_1', 'c')]*num_eval_samples\n",
        "\n",
        "    #replace place holder with real value for constant\n",
        "    #equations_MCMC = [e.replace(\"c_1\", str(round(c, 2))) for e, c in zip(equations_MCMC, constants_MCMC)]\n",
        "    df = {\n",
        "        \"y\": latent_variable_MCMC,\n",
        "        \"x\": x_values.tolist()*len(smpls['latent_variable_0']),\n",
        "        \"equation\": equations_MCMC\n",
        "\n",
        "    }\n",
        "\n",
        "    df_compare = {\n",
        "        'x': np.linspace(-1, 1, 50),\n",
        "        'y_sample': v_sample[1] ,\n",
        "        'y_real': v_real[1],\n",
        "        'y_random': v_random[1]\n",
        "    }\n",
        "    print(f\"the smallest constant is {min(constants_MCMC)} and the largest constant is {max(constants_MCMC)}\")\n",
        "\n",
        "    data = pd.DataFrame(df)\n",
        "    #plt.figure(figsize=(8, 6))\n",
        "    sns.scatterplot(data=df_compare, x='x', y='y_real', label=f\"Real: {target_function.replace('c_0', str(target_constant)).replace('x_1', 'x')}\", )\n",
        "    #g = sns.lineplot(data=data, x='x', y='y', hue='equation', fit_reg=True, legend=False, height=5, scatter_kws={'alpha':0.5, 's': 0.05})\n",
        "    sns.lineplot(data=data, x='x', y='y', hue='equation')\n",
        "    #sns.lineplot(data=df_compare, x='x', y='y_sample', label=f\"Sampled: {prefix_to_infix(result_equation, is_function, is_operator).replace('c_0', str(round(result_constant, 2)) )}\")\n",
        "    if with_Random:\n",
        "        sns.lineplot(data=df_compare, x='x', y='y_random', label=f\"Random: {prefix_to_infix(random_equation, is_function, is_operator).replace('c_0', str(round(random_constant, 2)) )}\")\n",
        "\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "jSyQvRxxcwz1",
      "metadata": {
        "id": "jSyQvRxxcwz1"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "def plot_interpolations(interpolated_df, assignment):\n",
        "    is_function= assignment[0]\n",
        "    is_operator = assignment[1]\n",
        "    is_var = assignment[2]\n",
        "    is_con = assignment[3]\n",
        "    colors = list(Color(\"green\").range_to(Color(\"blue\"), len(interpolated_df.values)))\n",
        "    equations = []\n",
        "    equations_infix = []\n",
        "    constants = []\n",
        "    values = []\n",
        "    for equation in interpolated_df.values:\n",
        "        value = generate_values(equation[5], equation[4][0][0], is_function, is_operator, is_var, is_con)\n",
        "        equation_prefix = infix_to_prefix(equation[5], is_function, is_operator,)\n",
        "        if len(value) == 2:\n",
        "            equations.append(equation_prefix)\n",
        "            equations_infix.append(equation[5])\n",
        "            constants.append(equation[4][0][0])\n",
        "            values.append(value)\n",
        "    if len(equations) > 0:\n",
        "        print(f\"{len(equations)} out of {len(interpolated_df.values)} equations were successfully evaluated\")\n",
        "        #print(f\"The two original functions ({equations_infix[0]} and ({equations_infix[-1]})) have a correlation of {np.corrcoef(values[0][1], values[-1][1])[0][1]}, a covariance of {np.cov(values[0][1], values[-1][1])[0][1]} and a distance of {np.linalg.norm(np.array(values[0][1]) - np.array(values[-1][1], ), ord=1)/25}\")\n",
        "        constants_f = [[float(c)] for c in constants]\n",
        "        fig = plot_functions(equations=equations, constants=constants_f, values=values, is_function=is_function, is_operator=is_operator,)\n",
        "\n",
        "    else:\n",
        "        fig = None\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VT9vnZUKsaZ5",
      "metadata": {
        "id": "VT9vnZUKsaZ5"
      },
      "source": [
        "# Create Dataset and Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mP2sZ_3qZ-TC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mP2sZ_3qZ-TC",
        "outputId": "f04ace38-7b60-426a-e235-b52c43741069"
      },
      "outputs": [],
      "source": [
        "from vaeesr import create_autoencoder, create_dataset\n",
        "function_space = [\"sin\", \"exp\", \"cos\", \"tan\", \"abs\", \"sqrt\", \"log\"]\n",
        "operator_space = [\"+\", \"-\", '*', \"/\", \"**\"]\n",
        "variable_space = [\"x_1\"]\n",
        "constant_space = [\"c_0\", \"c_1\"]\n",
        "\n",
        "spaces = (function_space, operator_space, variable_space, constant_space)\n",
        "\n",
        "# Create dataset\n",
        "train_loader, test_loader, test_size, dataset, classes, unique_symbols, max_len = create_dataset(spaces, num_equation_samples=num_equations, max_tree_depth=max_tree_depth)\n",
        "\n",
        "# Create autoencoder\n",
        "autoencoder, results = create_autoencoder(train_loader, test_loader, unique_symbols, test_size, max_len, classes, latent_dims=latent_dims)\n",
        "print(f\"There are a total of {len(classes)} classes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SiGZTQf0sf6u",
      "metadata": {
        "id": "SiGZTQf0sf6u"
      },
      "source": [
        "## Evaluate Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oh1SDbQVtHyl",
      "metadata": {
        "id": "oh1SDbQVtHyl"
      },
      "source": [
        "### Get number of classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "INLCfBMHZ-TD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INLCfBMHZ-TD",
        "outputId": "67e95472-e96c-44c6-845c-eeebf839fc04"
      },
      "outputs": [],
      "source": [
        "from equation_tree.util.conversions import infix_to_prefix, prefix_to_infix\n",
        "from vaeesr import mapping_from_spaces\n",
        "mapping  = mapping_from_spaces(spaces)\n",
        "print(f\"There are a total of {len(classes)} classes\")\n",
        "[prefix_to_infix(dataset.decode_equation(c), mapping[0], mapping[1]) for c in classes]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RmY2RJJqtNfq",
      "metadata": {
        "id": "RmY2RJJqtNfq"
      },
      "source": [
        "### Plot Loss functions and Correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6x3_Xsi6Z-TG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "6x3_Xsi6Z-TG",
        "outputId": "458eecfd-69d0-4aff-906a-8a0c4f00ecd0"
      },
      "outputs": [],
      "source": [
        "from vaeesr import VAE_classify\n",
        "import matplotlib.pyplot as plt\n",
        "#print(f\"correlation distance of last epoch: {best_correlation_dis}\")\n",
        "#print(f\"correlation correlation of last epoch: {best_correlation_cor}\")\n",
        "if type(autoencoder) == VAE_classify:\n",
        "    df = results\n",
        "else:\n",
        "    df = None\n",
        "\n",
        "plot_losses(\n",
        "    results[\"train_losses\"],\n",
        "    results[\"test_losses\"],\n",
        "   correlation_dis=results[\"correlation_dis\"],\n",
        "    df = df,\n",
        ")\n",
        "#last_correlations_cor = np.sum(correlations_cor[-10:]) / 10\n",
        "#last_correlations_dis = np.sum(correlations_dis[-10:]) / 10\n",
        "#print(f\"Last 10 epochs average correlation: {last_correlations_cor}\")\n",
        "#print(f\"Last 10 epochs average correlation: {last_correlations_dis}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PiIAINJFtSRq",
      "metadata": {
        "id": "PiIAINJFtSRq"
      },
      "source": [
        "### Reconstruction Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-DUunLHUZ-TI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DUunLHUZ-TI",
        "outputId": "13734db0-cdc8-420a-ee3e-0d0468f48e11"
      },
      "outputs": [],
      "source": [
        "%reload_ext autoreload\n",
        "from vaeesr import evaluation, get_latent_representation,get_interpolated_df\n",
        "from equation_tree.util.conversions import prefix_to_infix\n",
        "\n",
        "evaluation(results, dataset, max_len, classes)\n",
        "#evaluation_ecv(results['x_batches'], results['x_hat_batches'], dataset, max_len, 'VAE_C')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1JCz5SCtW7F",
      "metadata": {
        "id": "e1JCz5SCtW7F"
      },
      "source": [
        "### Minimum and Maximum Embedding Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kNdhxEpTZ-TJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNdhxEpTZ-TJ",
        "outputId": "2d624241-3702-4d6d-a9ca-00e221e8ac4b"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "test_equations =[]\n",
        "test_constants = []\n",
        "for batch in test_loader:\n",
        "    test_equations += batch[0]\n",
        "    test_constants += batch[1]\n",
        "\n",
        "\n",
        "latent_space_representation, test_values, = get_latent_representation(\n",
        "    model=autoencoder,\n",
        "    device=device,\n",
        "    test_dataloader=test_loader,\n",
        "    x_batches_p=results['x_batches'],\n",
        "    x_hat_batches_p=results['x_hat_batches'],\n",
        "    equation_tree_dataset=dataset,\n",
        "    num_interpolations=5\n",
        ")\n",
        "\n",
        "latent_space_min_max = []\n",
        "for i in range(latent_space_representation.shape[1]):\n",
        "    latent_space_min_max.append((latent_space_representation[:, i].min(), latent_space_representation[:, i].max()))\n",
        "\n",
        "print(latent_space_min_max)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sqeAwB8mtd7w",
      "metadata": {
        "id": "sqeAwB8mtd7w"
      },
      "source": [
        "### Plot Latent Space Representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "yTD6ebtKZ-TK",
      "metadata": {
        "id": "yTD6ebtKZ-TK"
      },
      "outputs": [],
      "source": [
        "from equation_tree.util.conversions import prefix_to_infix\n",
        "\n",
        "mapping = mapping_from_spaces(spaces)\n",
        "df = {\n",
        "    \"category\": [prefix_to_infix(dataset.decode_equation(eq.tolist()), mapping[0], mapping[1]).replace(\"c_1\", str(round(float(const[0]),2))) for eq, const in zip(test_equations, test_constants)],\n",
        "}\n",
        "\n",
        "for i in range(latent_space_representation.shape[1]):\n",
        "    df[\"x_\" + str(i)] = latent_space_representation[:, i]\n",
        "\n",
        "df = pd.DataFrame(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5F5p5L4WZ-TL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "5F5p5L4WZ-TL",
        "outputId": "382c507e-6244-4b36-e2de-0e4b38baf268"
      },
      "outputs": [],
      "source": [
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.scatterplot(df, x=\"x_0\", y=\"x_1\",hue='category', legend=False, palette=\"tab10\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "j4cEuVD5tjim",
      "metadata": {
        "id": "j4cEuVD5tjim"
      },
      "source": [
        "### Plot interpolations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "japrD974Z-TL",
      "metadata": {
        "id": "japrD974Z-TL",
        "outputId": "2285b7ef-eb6b-4b82-9b48-1a941d9dd878"
      },
      "outputs": [],
      "source": [
        "%autoreload\n",
        "from vaeesr import  generate_values, try_infix\n",
        "from colour import Color\n",
        "\n",
        "for i in range(1):\n",
        "    rand_idx1 = random.randint(0, len(test_equations))\n",
        "    rand_idx2 = random.randint(0, len(test_equations))\n",
        "    df, _ = get_interpolated_df(\n",
        "        kind=\"classifier\",\n",
        "        model=autoencoder,\n",
        "        equation_tree_dataset=dataset,\n",
        "        latent_space_representation=latent_space_representation,\n",
        "        equation_1=rand_idx1,\n",
        "        equation_2=rand_idx2,\n",
        "        c_1=1.5,\n",
        "        c_2=0.5,\n",
        "        num_interpolations=20,\n",
        "        assignment=mapping,\n",
        "        classes=classes,\n",
        "    )\n",
        "    if len(df.values)> 0:\n",
        "        fig = plot_interpolations(df, assignment=mapping)\n",
        "        fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b5rxhjPswge",
      "metadata": {
        "id": "3b5rxhjPswge"
      },
      "source": [
        "# MCMC sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LfQXtY0iZ-TG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfQXtY0iZ-TG",
        "outputId": "f29f1bab-3709-4fac-e71b-8951cbfebf8e"
      },
      "outputs": [],
      "source": [
        "from vaeesr import perform_MCMC\n",
        "from vaeesr import mapping_from_spaces, generate_values\n",
        "import pyro\n",
        "import pyro.distributions as dist\n",
        "#from base_folder.vaeesr.evaluation import decode_latent_classify\n",
        "\n",
        "mapping = mapping_from_spaces(spaces)\n",
        "#target_function = \"(c_0-x_1)*exp(x_1)\"\n",
        "#target_function = \"exp(x_1)*c_0\"\n",
        "#target_function = \"x_1+exp(x_1)+c_0\"\n",
        "\n",
        "# example function that generates the data (in practice this is the real underlying function that is unkown and only the target_dist would be available)\n",
        "target_function = \"c_0*x_1\"\n",
        "num_samples = 1000\n",
        "warmup_steps = 200\n",
        "target_constant = 2.0\n",
        "\n",
        "num_chains = 4\n",
        "target_dist = generate_values(target_function, target_constant, mapping[0], mapping[1], mapping[2], mapping[3])\n",
        "\n",
        "samples, mcmc = perform_MCMC(autoencoder, torch.tensor(target_dist, dtype=torch.float32), latent_dims, dataset, classes, spaces, num_samples=num_samples, warmup_steps=warmup_steps, num_chains=num_chains)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OVL1HP-xs3Ct",
      "metadata": {
        "id": "OVL1HP-xs3Ct"
      },
      "source": [
        "## Evaluate MCMC results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AmynRgnKtrGt",
      "metadata": {
        "id": "AmynRgnKtrGt"
      },
      "source": [
        "### Plot resulting Functions and Distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "198466e1",
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip3 install datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2WzrOqMIZ-TG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WzrOqMIZ-TG",
        "outputId": "886c0fca-0ad1-4098-db8c-7167edccdb73"
      },
      "outputs": [],
      "source": [
        "from equation_tree.util.conversions import infix_to_prefix, prefix_to_infix\n",
        "from vaeesr import evaluate_sampling\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "is_function, is_operator, is_variable, is_constant = mapping_from_spaces(spaces)\n",
        "v_real = generate_values(target_function, target_constant, is_function, is_operator, is_variable, is_constant)\n",
        "mean_equations, sampled_equations, random_equations = evaluate_sampling(samples, autoencoder, dataset, classes, latent_dims, spaces)\n",
        "print(f\"resulting function: {prefix_to_infix(mean_equations[0], is_function, is_operator)} with constant {mean_equations[1]}\")\n",
        "\n",
        "samples_df = pd.DataFrame(samples)\n",
        "parameters = {\n",
        "    'max_tree_depth': max_tree_depth,\n",
        "    'chains': num_chains,\n",
        "    'latent_dims': latent_dims,\n",
        "    'num_samples': num_samples,\n",
        "    'warmup_steps': warmup_steps,\n",
        "    'target_function': target_function,\n",
        "    'target_constant': target_constant,\n",
        "    'target_dist': target_dist,\n",
        "    'x_values': np.linspace(-1, 1, 50).tolist(),\n",
        "    'spaces': spaces,\n",
        "    'num_equations': num_equations,\n",
        "    'classes': [prefix_to_infix(dataset.decode_equation(c), mapping[0], mapping[1]) for c in classes],\n",
        "}\n",
        "with open(f'results/parameters_{datetime.now().replace(microsecond=0)}.json', 'w') as json_file:\n",
        "    json.dump(parameters, json_file, indent=4, ensure_ascii=False)\n",
        "samples_df.to_csv(f\"results/results_{datetime.now().replace(microsecond=0)}.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UJ5_Nng_Z-TH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 900
        },
        "id": "UJ5_Nng_Z-TH",
        "outputId": "597fd128-d19e-4e63-b09d-635fdde8512f"
      },
      "outputs": [],
      "source": [
        "#from base_folder.vaeesr.utils import plot_dist, plot_sampling_functions\n",
        "import seaborn as sns\n",
        "plot_sampling_functions(samples, False, latent_dims, spaces, autoencoder, dataset, classes, 50, mean_equations[2], v_real, random_equations[2], target_constant, target_function, np.linspace(-1.0, 1.0, 50))\n",
        "plot_dist(samples)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
